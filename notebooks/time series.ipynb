{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import gc\n",
    "from bib import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K \n",
    "from keras import  activations\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Dense, Activation, regularizers,BatchNormalization,Dropout\n",
    "import tensorflow as tf\n",
    "from  tqdm import tqdm_notebook\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lb = scipy.io.loadmat(dataPath +'VectLB19922008.mat')\n",
    "labels = [k[0] for k in lb['labels'][0] ]\n",
    "data=pd.DataFrame(lb['Vect'],columns=labels)\n",
    "data['time']= data['year']*100+data['5days']\n",
    "data=data.sort_values('time')\n",
    "values=data.loc[:,['CHL '+ str(i) for i in range(2,19)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times=np.sort(list(set(data['time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "for i in range(len(times)-1):\n",
    "    X.append(values.loc[data['time']==times[i],:].values)\n",
    "    y.append(values.loc[data['time']==times[i+1],:].values)\n",
    "X=np.array(X).reshape((-1,17))\n",
    "y=np.array(y).reshape((-1,17))\n",
    "# X=np.log(X)\n",
    "# y=np.log(y)/np.log(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xt=X[data['year'][:-9]!=2008]\n",
    "Yt=y[data['year'][:-9]!=2008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate(arch,act):\n",
    "    layers=[]\n",
    "    for index,size in enumerate(arch):\n",
    "        if index ==0:\n",
    "            layers.append(Dense(size, input_shape=(17,),activation=act[index]))\n",
    "#             layers.append(BatchNormalization())\n",
    "\n",
    "        else:\n",
    "            layers.append(Dense(size,activation=act[index]))\n",
    "#             layers.append(Dropout(0.3))\n",
    "    layers.append(Dense(17,activation='linear',kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model = Sequential(layers)\n",
    "    model.compile(optimizer='Adam',\n",
    "              loss='mse')\n",
    "    return model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(arch,act,X,y):\n",
    "    fold_evaluation=[]\n",
    "    for k in tqdm_notebook(range(1992,2008),leave=False):\n",
    "        center=np.logical_and(np.logical_and(np.logical_and(data['latitude']<=33, data['latitude']>=31 ), data['longitude']>=-65 ), data['longitude']<=-63 )\n",
    "        xv=X[np.logical_and(data['year'][:-657]==k,center[:-657])]\n",
    "        yv=y[np.logical_and(data['year'][:-657]==k,center[:-657])]\n",
    "        xt=X[data['year'][:-657]!=k]\n",
    "        yt=y[data['year'][:-657]!=k]\n",
    "        \n",
    "        model=generate(arch,act)\n",
    "        mean=xt.mean()\n",
    "        std=xt.std()\n",
    "        xt=(xt-mean)/std\n",
    "        xv=(xv-mean)/std\n",
    "        \n",
    "        model.fit(xt,yt,\n",
    "          epochs=10000,\n",
    "          callbacks=callbacks,\n",
    "          verbose=0,\n",
    "          batch_size=73*10, \n",
    "          validation_data=(xv,yv))\n",
    "        yp = model.predict(xv)\n",
    "        \n",
    "#         yp=np.exp(yp*np.log(10))\n",
    "#         yv=np.exp(yv*np.log(10))  \n",
    "        fold_evaluation.append(evaluate(yp,yv))\n",
    "        print(evaluate(yp,yv))\n",
    "    return np.mean(fold_evaluation),np.std(fold_evaluation )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARCH :(1000, 500, 1000, 1000, 1000, 2000)\n",
      "0.09822339577323709\n",
      "0.0878315320255171\n",
      "0.08620101106937429\n",
      "0.10935962372227462\n",
      "0.096844111363202\n",
      "0.0881275502091666\n",
      "0.08337590261658655\n",
      "0.08803039629329913\n",
      "0.09209774298391891\n",
      "0.09688925094847614\n",
      "0.07479610010307873\n",
      "0.07485244749058602\n",
      "0.08721460060279106\n",
      "0.09841504360655415\n",
      "0.09169788441141498\n",
      "0.07536467709407466\n",
      "\t error: 0.08933 +- 0.00922\n"
     ]
    }
   ],
   "source": [
    "arch=(1000, 500, 1000, 1000, 1000, 2000)\n",
    "K.clear_session()\n",
    "print('ARCH :'+ str(arch))\n",
    "# print('ACT :'+ str(act))\n",
    "error,std=validate(arch,['softplus']*len(arch),Xt,Yt)\n",
    "print('\\t error: %.5f +- %.5f' % (error,std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9855 samples, validate on 657 samples\n",
      "Epoch 1/10000\n",
      "9855/9855 [==============================] - 1s 77us/step - loss: 5.4135 - val_loss: 1.0076\n",
      "Epoch 2/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.7922 - val_loss: 0.5383\n",
      "Epoch 3/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.4492 - val_loss: 0.4009\n",
      "Epoch 4/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.3690 - val_loss: 0.3631\n",
      "Epoch 5/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.3482 - val_loss: 0.3534\n",
      "Epoch 6/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.3400 - val_loss: 0.3463\n",
      "Epoch 7/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.3345 - val_loss: 0.3416\n",
      "Epoch 8/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.3293 - val_loss: 0.3354\n",
      "Epoch 9/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.3233 - val_loss: 0.3277\n",
      "Epoch 10/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.3149 - val_loss: 0.3169\n",
      "Epoch 11/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.3059 - val_loss: 0.3088\n",
      "Epoch 12/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.3001 - val_loss: 0.3037\n",
      "Epoch 13/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.2948 - val_loss: 0.2985\n",
      "Epoch 14/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2897 - val_loss: 0.2934\n",
      "Epoch 15/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2847 - val_loss: 0.2883\n",
      "Epoch 16/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.2797 - val_loss: 0.2834\n",
      "Epoch 17/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.2747 - val_loss: 0.2782\n",
      "Epoch 18/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2697 - val_loss: 0.2734\n",
      "Epoch 19/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.2648 - val_loss: 0.2682\n",
      "Epoch 20/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2598 - val_loss: 0.2632\n",
      "Epoch 21/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2549 - val_loss: 0.2585\n",
      "Epoch 22/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2500 - val_loss: 0.2533\n",
      "Epoch 23/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2451 - val_loss: 0.2487\n",
      "Epoch 24/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2403 - val_loss: 0.2436\n",
      "Epoch 25/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2355 - val_loss: 0.2390\n",
      "Epoch 26/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.2308 - val_loss: 0.2336\n",
      "Epoch 27/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2260 - val_loss: 0.2290\n",
      "Epoch 28/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2214 - val_loss: 0.2243\n",
      "Epoch 29/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2168 - val_loss: 0.2197\n",
      "Epoch 30/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2122 - val_loss: 0.2147\n",
      "Epoch 31/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.2077 - val_loss: 0.2104\n",
      "Epoch 32/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2033 - val_loss: 0.2056\n",
      "Epoch 33/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1989 - val_loss: 0.2012\n",
      "Epoch 34/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1946 - val_loss: 0.1966\n",
      "Epoch 35/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1903 - val_loss: 0.1922\n",
      "Epoch 36/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1861 - val_loss: 0.1877\n",
      "Epoch 37/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1820 - val_loss: 0.1835\n",
      "Epoch 38/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1779 - val_loss: 0.1793\n",
      "Epoch 39/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1739 - val_loss: 0.1753\n",
      "Epoch 40/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1700 - val_loss: 0.1713\n",
      "Epoch 41/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1662 - val_loss: 0.1675\n",
      "Epoch 42/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1624 - val_loss: 0.1637\n",
      "Epoch 43/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1587 - val_loss: 0.1600\n",
      "Epoch 44/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1551 - val_loss: 0.1563\n",
      "Epoch 45/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.1515 - val_loss: 0.1527\n",
      "Epoch 46/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1480 - val_loss: 0.1492\n",
      "Epoch 47/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1446 - val_loss: 0.1457\n",
      "Epoch 48/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1412 - val_loss: 0.1424\n",
      "Epoch 49/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1379 - val_loss: 0.1392\n",
      "Epoch 50/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1347 - val_loss: 0.1358\n",
      "Epoch 51/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1316 - val_loss: 0.1327\n",
      "Epoch 52/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1285 - val_loss: 0.1297\n",
      "Epoch 53/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1255 - val_loss: 0.1268\n",
      "Epoch 54/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1226 - val_loss: 0.1240\n",
      "Epoch 55/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1198 - val_loss: 0.1210\n",
      "Epoch 56/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1170 - val_loss: 0.1182\n",
      "Epoch 57/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1142 - val_loss: 0.1157\n",
      "Epoch 58/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1117 - val_loss: 0.1130\n",
      "Epoch 59/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1090 - val_loss: 0.1104\n",
      "Epoch 60/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1064 - val_loss: 0.1078\n",
      "Epoch 61/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1040 - val_loss: 0.1054\n",
      "Epoch 62/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.1016 - val_loss: 0.1032\n",
      "Epoch 63/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0992 - val_loss: 0.1007\n",
      "Epoch 64/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0968 - val_loss: 0.0984\n",
      "Epoch 65/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0946 - val_loss: 0.0962\n",
      "Epoch 66/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0923 - val_loss: 0.0940\n",
      "Epoch 67/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0902 - val_loss: 0.0919\n",
      "Epoch 68/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0881 - val_loss: 0.0898\n",
      "Epoch 69/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0860 - val_loss: 0.0877\n",
      "Epoch 70/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0839 - val_loss: 0.0856\n",
      "Epoch 71/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0819 - val_loss: 0.0837\n",
      "Epoch 72/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0800 - val_loss: 0.0818\n",
      "Epoch 73/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0781 - val_loss: 0.0799\n",
      "Epoch 74/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0763 - val_loss: 0.0781\n",
      "Epoch 75/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0745 - val_loss: 0.0764\n",
      "Epoch 76/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0727 - val_loss: 0.0746\n",
      "Epoch 77/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0710 - val_loss: 0.0731\n",
      "Epoch 78/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0694 - val_loss: 0.0712\n",
      "Epoch 79/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0677 - val_loss: 0.0696\n",
      "Epoch 80/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0661 - val_loss: 0.0681\n",
      "Epoch 81/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0645 - val_loss: 0.0665\n",
      "Epoch 82/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0630 - val_loss: 0.0651\n",
      "Epoch 83/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0615 - val_loss: 0.0635\n",
      "Epoch 84/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0601 - val_loss: 0.0622\n",
      "Epoch 85/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0587 - val_loss: 0.0607\n",
      "Epoch 86/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0573 - val_loss: 0.0593\n",
      "Epoch 87/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.0560 - val_loss: 0.0581\n",
      "Epoch 88/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0546 - val_loss: 0.0567\n",
      "Epoch 89/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0534 - val_loss: 0.0554\n",
      "Epoch 90/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0521 - val_loss: 0.0543\n",
      "Epoch 91/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0509 - val_loss: 0.0531\n",
      "Epoch 92/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0498 - val_loss: 0.0519\n",
      "Epoch 93/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0486 - val_loss: 0.0507\n",
      "Epoch 94/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.0475 - val_loss: 0.0495\n",
      "Epoch 95/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0463 - val_loss: 0.0486\n",
      "Epoch 96/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0453 - val_loss: 0.0475\n",
      "Epoch 97/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0442 - val_loss: 0.0465\n",
      "Epoch 98/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0433 - val_loss: 0.0455\n",
      "Epoch 99/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0423 - val_loss: 0.0446\n",
      "Epoch 100/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0414 - val_loss: 0.0435\n",
      "Epoch 101/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0403 - val_loss: 0.0426\n",
      "Epoch 102/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0395 - val_loss: 0.0418\n",
      "Epoch 103/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0385 - val_loss: 0.0408\n",
      "Epoch 104/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0377 - val_loss: 0.0399\n",
      "Epoch 105/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0369 - val_loss: 0.0391\n",
      "Epoch 106/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0361 - val_loss: 0.0385\n",
      "Epoch 107/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0353 - val_loss: 0.0375\n",
      "Epoch 108/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0345 - val_loss: 0.0368\n",
      "Epoch 109/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0337 - val_loss: 0.0359\n",
      "Epoch 110/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0331 - val_loss: 0.0354\n",
      "Epoch 111/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0324 - val_loss: 0.0348\n",
      "Epoch 112/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0317 - val_loss: 0.0339\n",
      "Epoch 113/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0309 - val_loss: 0.0333\n",
      "Epoch 114/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0302 - val_loss: 0.0324\n",
      "Epoch 115/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0295 - val_loss: 0.0318\n",
      "Epoch 116/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0289 - val_loss: 0.0312\n",
      "Epoch 117/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0282 - val_loss: 0.0308\n",
      "Epoch 118/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0278 - val_loss: 0.0303\n",
      "Epoch 119/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0272 - val_loss: 0.0296\n",
      "Epoch 120/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0265 - val_loss: 0.0290\n",
      "Epoch 121/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0261 - val_loss: 0.0287\n",
      "Epoch 122/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0256 - val_loss: 0.0278\n",
      "Epoch 123/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0250 - val_loss: 0.0273\n",
      "Epoch 124/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0244 - val_loss: 0.0267\n",
      "Epoch 125/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0239 - val_loss: 0.0265\n",
      "Epoch 126/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0235 - val_loss: 0.0259\n",
      "Epoch 127/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0231 - val_loss: 0.0256\n",
      "Epoch 128/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0227 - val_loss: 0.0253\n",
      "Epoch 129/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0222 - val_loss: 0.0245\n",
      "Epoch 130/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0217 - val_loss: 0.0242\n",
      "Epoch 131/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0212 - val_loss: 0.0237\n",
      "Epoch 132/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0208 - val_loss: 0.0236\n",
      "Epoch 133/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0206 - val_loss: 0.0229\n",
      "Epoch 134/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0204 - val_loss: 0.0229\n",
      "Epoch 135/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0199 - val_loss: 0.0224\n",
      "Epoch 136/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0194 - val_loss: 0.0218\n",
      "Epoch 137/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0191 - val_loss: 0.0216\n",
      "Epoch 138/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0187 - val_loss: 0.0211\n",
      "Epoch 139/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0183 - val_loss: 0.0208\n",
      "Epoch 140/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0180 - val_loss: 0.0206\n",
      "Epoch 141/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0177 - val_loss: 0.0201\n",
      "Epoch 142/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0174 - val_loss: 0.0202\n",
      "Epoch 143/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0173 - val_loss: 0.0201\n",
      "Epoch 144/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0172 - val_loss: 0.0198\n",
      "Epoch 145/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0168 - val_loss: 0.0191\n",
      "Epoch 146/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0164 - val_loss: 0.0188\n",
      "Epoch 147/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0163 - val_loss: 0.0187\n",
      "Epoch 148/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0158 - val_loss: 0.0183\n",
      "Epoch 149/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0155 - val_loss: 0.0180\n",
      "Epoch 150/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0154 - val_loss: 0.0178\n",
      "Epoch 151/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0151 - val_loss: 0.0174\n",
      "Epoch 152/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0148 - val_loss: 0.0172\n",
      "Epoch 153/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0146 - val_loss: 0.0170\n",
      "Epoch 154/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0143 - val_loss: 0.0167\n",
      "Epoch 155/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0142 - val_loss: 0.0167\n",
      "Epoch 156/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0142 - val_loss: 0.0164\n",
      "Epoch 157/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0138 - val_loss: 0.0161\n",
      "Epoch 158/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0136 - val_loss: 0.0161\n",
      "Epoch 159/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0134 - val_loss: 0.0159\n",
      "Epoch 160/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0133 - val_loss: 0.0158\n",
      "Epoch 161/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0132 - val_loss: 0.0157\n",
      "Epoch 162/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0131 - val_loss: 0.0154\n",
      "Epoch 163/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0128 - val_loss: 0.0152\n",
      "Epoch 164/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0125 - val_loss: 0.0149\n",
      "Epoch 165/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0123 - val_loss: 0.0148\n",
      "Epoch 166/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0124 - val_loss: 0.0150\n",
      "Epoch 167/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 168/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0151\n",
      "Epoch 169/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 170/10000\n",
      "9855/9855 [==============================] - 0s 21us/step - loss: 0.0118 - val_loss: 0.0142\n",
      "Epoch 171/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0116 - val_loss: 0.0143\n",
      "Epoch 172/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0116 - val_loss: 0.0140\n",
      "Epoch 173/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0114 - val_loss: 0.0138\n",
      "Epoch 174/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0113 - val_loss: 0.0138\n",
      "Epoch 175/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0112 - val_loss: 0.0134\n",
      "Epoch 176/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0110 - val_loss: 0.0135\n",
      "Epoch 177/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0110 - val_loss: 0.0135\n",
      "Epoch 178/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 179/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.0109 - val_loss: 0.0133\n",
      "Epoch 180/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0109 - val_loss: 0.0134\n",
      "Epoch 181/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 182/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0105 - val_loss: 0.0131\n",
      "Epoch 183/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0103 - val_loss: 0.0127\n",
      "Epoch 184/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0102 - val_loss: 0.0127\n",
      "Epoch 185/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0102 - val_loss: 0.0125\n",
      "Epoch 186/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0101 - val_loss: 0.0128\n",
      "Epoch 187/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0101 - val_loss: 0.0124\n",
      "Epoch 188/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0100 - val_loss: 0.0124\n",
      "Epoch 189/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0101 - val_loss: 0.0124\n",
      "Epoch 190/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0101 - val_loss: 0.0128\n",
      "Epoch 191/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0099 - val_loss: 0.0123\n",
      "Epoch 192/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0098 - val_loss: 0.0122\n",
      "Epoch 193/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0096 - val_loss: 0.0122\n",
      "Epoch 194/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0096 - val_loss: 0.0122\n",
      "Epoch 195/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0096 - val_loss: 0.0119\n",
      "Epoch 196/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0095 - val_loss: 0.0118\n",
      "Epoch 197/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0094 - val_loss: 0.0118\n",
      "Epoch 198/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0094 - val_loss: 0.0118\n",
      "Epoch 199/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0094 - val_loss: 0.0118\n",
      "Epoch 200/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0094 - val_loss: 0.0119\n",
      "Epoch 201/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0093 - val_loss: 0.0118\n",
      "Epoch 202/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0093 - val_loss: 0.0117\n",
      "Epoch 203/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0091 - val_loss: 0.0114\n",
      "Epoch 204/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0090 - val_loss: 0.0118\n",
      "Epoch 205/10000\n",
      "9855/9855 [==============================] - 0s 20us/step - loss: 0.0092 - val_loss: 0.0115\n",
      "Epoch 206/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0090 - val_loss: 0.0113\n",
      "Epoch 207/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0089 - val_loss: 0.0116\n",
      "Epoch 208/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0090 - val_loss: 0.0116\n",
      "Epoch 209/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0090 - val_loss: 0.0117\n",
      "Epoch 210/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0090 - val_loss: 0.0115\n",
      "Epoch 211/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0089 - val_loss: 0.0111\n",
      "Epoch 212/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0087 - val_loss: 0.0111\n",
      "Epoch 213/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0088 - val_loss: 0.0114\n",
      "Epoch 214/10000\n",
      "9855/9855 [==============================] - 0s 20us/step - loss: 0.0087 - val_loss: 0.0111\n",
      "Epoch 215/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0087 - val_loss: 0.0114\n",
      "Epoch 216/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0088 - val_loss: 0.0112\n",
      "Epoch 217/10000\n",
      "9855/9855 [==============================] - 0s 20us/step - loss: 0.0087 - val_loss: 0.0110\n",
      "Epoch 218/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0086 - val_loss: 0.0110\n",
      "Epoch 219/10000\n",
      "9855/9855 [==============================] - 0s 21us/step - loss: 0.0086 - val_loss: 0.0110\n",
      "Epoch 220/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.0085 - val_loss: 0.0112\n",
      "Epoch 221/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.0086 - val_loss: 0.0110\n",
      "Epoch 222/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0085 - val_loss: 0.0109\n",
      "Epoch 223/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0085 - val_loss: 0.0113\n",
      "Epoch 224/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0084 - val_loss: 0.0109\n",
      "Epoch 225/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0085 - val_loss: 0.0109\n",
      "Epoch 226/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.0084 - val_loss: 0.0112\n",
      "Epoch 227/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0087 - val_loss: 0.0111\n",
      "Epoch 228/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0084 - val_loss: 0.0108\n",
      "Epoch 229/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 230/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0085 - val_loss: 0.0112\n",
      "Epoch 231/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0084 - val_loss: 0.0110\n",
      "Epoch 232/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0083 - val_loss: 0.0107\n",
      "Epoch 233/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0084 - val_loss: 0.0111\n",
      "Epoch 234/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0084 - val_loss: 0.0108\n",
      "Epoch 235/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 236/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0083 - val_loss: 0.0107\n",
      "Epoch 237/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0084 - val_loss: 0.0109\n",
      "Epoch 238/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0082 - val_loss: 0.0112\n",
      "Epoch 239/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0082 - val_loss: 0.0107\n",
      "Epoch 240/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0081 - val_loss: 0.0109\n",
      "Epoch 241/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 242/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 243/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0082 - val_loss: 0.0108\n",
      "Epoch 244/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 245/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0108\n",
      "Epoch 246/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0081 - val_loss: 0.0109\n",
      "Epoch 247/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0083 - val_loss: 0.0108\n",
      "Epoch 248/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 249/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 250/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 251/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 252/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 253/10000\n",
      "9855/9855 [==============================] - 0s 20us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 254/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 255/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0081 - val_loss: 0.0103\n",
      "Epoch 256/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0109\n",
      "Epoch 257/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.0082 - val_loss: 0.0108\n",
      "Epoch 258/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 259/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 260/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 261/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 262/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 263/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 264/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 265/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 266/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 267/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 268/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 269/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0102\n",
      "Epoch 270/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 271/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 272/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 273/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0107\n",
      "Epoch 274/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 275/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 276/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 277/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0079 - val_loss: 0.0102\n",
      "Epoch 278/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 279/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 280/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 281/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 282/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 283/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 284/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 285/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 286/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 287/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 288/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 289/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 290/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 291/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 292/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 293/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 294/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 295/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 296/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 297/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 298/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 299/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 300/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 301/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 302/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 303/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 304/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 305/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 306/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 307/10000\n",
      "9855/9855 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad1cfb4208>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=1995\n",
    "arch=(1000, 1000, 2000)\n",
    "K.clear_session()\n",
    "xv=Xt[data['year'][:-657]==k]\n",
    "yv=Yt[data['year'][:-657]==k]\n",
    "xt=Xt[data['year'][:-657]!=k]\n",
    "yt=Yt[data['year'][:-657]!=k]\n",
    "model=generate(arch,['softplus']*len(arch))\n",
    "mean=xt.mean()\n",
    "std=xt.std()\n",
    "xt=(xt-mean)/std\n",
    "xv=(xv-mean)/std\n",
    "model.fit(xt,yt,\n",
    "  epochs=10000,\n",
    "  callbacks=callbacks,\n",
    "  verbose=1,\n",
    "  batch_size=73*10, \n",
    "  validation_data=(xv,yv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor Tensor(\"dense_4/BiasAdd:0\", shape=(?, 17), dtype=float32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-2cf50af28f97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mxt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0myp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0myp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myp\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1746\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_predict_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m                                                \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_updates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                                                \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'predict_function'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m                                                **kwargs)\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'steps'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m   2354\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Invalid argument \"%s\" passed to K.function with TensorFlow backend'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2355\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2356\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, updates, name, **session_kwargs)\u001b[0m\n\u001b[1;32m   2303\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2304\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2305\u001b[0;31m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2306\u001b[0m             \u001b[0mupdates_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2307\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[0;34m(control_inputs)\u001b[0m\n\u001b[1;32m   5026\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mNullContextmanager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   5027\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5028\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrol_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   5030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[0;34m(self, control_inputs)\u001b[0m\n\u001b[1;32m   4526\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexedSlices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4527\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4528\u001b[0;31m       \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4529\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4530\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3480\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3555\u001b[0m       \u001b[1;31m# Actually obj is just the object it's referring to.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3556\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3559\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOperation\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"dense_4/BiasAdd:0\", shape=(?, 17), dtype=float32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "xv=Xt[data['year'][:-657]==k].copy()\n",
    "yv=Yt[data['year'][:-657]==k].copy()\n",
    "xt=Xt[data['year'][:-657]!=k].copy()\n",
    "yt=Yt[data['year'][:-657]!=k].copy()\n",
    "\n",
    "mean=xt.mean()\n",
    "std=xt.std()\n",
    "xt=(xt-mean)/std\n",
    "yp = model.predict(xv)\n",
    "\n",
    "yp=np.exp(yp*np.log(10))\n",
    "yv=np.exp(yv*np.log(10))  \n",
    "evaluate(yp,yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
