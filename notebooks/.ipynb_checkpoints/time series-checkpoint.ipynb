{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import gc\n",
    "from bib import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K \n",
    "from keras import  activations\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Dense, Activation, regularizers,BatchNormalization,Dropout\n",
    "import tensorflow as tf\n",
    "from  tqdm import tqdm_notebook\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lb = scipy.io.loadmat(dataPath +'VectLB19922008.mat')\n",
    "labels = [k[0] for k in lb['labels'][0] ]\n",
    "data=pd.DataFrame(lb['Vect'],columns=labels)\n",
    "data['time']= data['year']*100+data['5days']\n",
    "data=data.sort_values('time')\n",
    "values=data.loc[:,['CHL '+ str(i) for i in range(2,19)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "for i in range(len(values)-1):\n",
    "    X.append(values.iloc[i,:].values)\n",
    "    y.append(values.iloc[i+1,:].values)\n",
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "# X=np.log(X)\n",
    "# y=np.log(y)/np.log(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xt=X[data['year'][:-1]!=2008]\n",
    "Yt=y[data['year'][:-1]!=2008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate(arch,act):\n",
    "    layers=[]\n",
    "    for index,size in enumerate(arch):\n",
    "        if index ==0:\n",
    "            layers.append(Dense(size, input_shape=(17,),activation=act[index]))\n",
    "#             layers.append(BatchNormalization())\n",
    "\n",
    "        else:\n",
    "            layers.append(Dense(size,activation=act[index]))\n",
    "#             layers.append(Dropout(0.3))\n",
    "    layers.append(Dense(17,activation='linear',kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model = Sequential(layers)\n",
    "    model.compile(optimizer='Adam',\n",
    "              loss='mse')\n",
    "    return model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(arch,act,X,y):\n",
    "    fold_evaluation=[]\n",
    "    for k in tqdm_notebook(range(1992,2008),leave=False):\n",
    "        xv=X[data['year'][:-657]==k]\n",
    "        yv=y[data['year'][:-657]==k]\n",
    "        xt=X[data['year'][:-657]!=k]\n",
    "        yt=y[data['year'][:-657]!=k]\n",
    "        \n",
    "        model=generate(arch,act)\n",
    "        mean=xt.mean()\n",
    "        std=xt.std()\n",
    "        xt=(xt-mean)/std\n",
    "        xv=(xv-mean)/std\n",
    "        \n",
    "        model.fit(xt,yt,\n",
    "          epochs=10000,\n",
    "          callbacks=callbacks,\n",
    "          verbose=0,\n",
    "          batch_size=73*10, \n",
    "          validation_data=(xv,yv))\n",
    "        yp = model.predict(xv)\n",
    "        \n",
    "#         yp=np.exp(yp*np.log(10))\n",
    "#         yv=np.exp(yv*np.log(10))  \n",
    "        fold_evaluation.append(evaluate(yp,yv))\n",
    "        print(evaluate(yp,yv))\n",
    "    return np.mean(fold_evaluation),np.std(fold_evaluation )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARCH :(1000, 500, 500, 500, 1000, 2000)\n"
     ]
    }
   ],
   "source": [
    "arch=(1000, 500, 500, 500, 1000, 2000)\n",
    "K.clear_session()\n",
    "print('ARCH :'+ str(arch))\n",
    "# print('ACT :'+ str(act))\n",
    "error,std=validate(arch,['softplus']*len(arch),Xt,Yt)\n",
    "print('\\t error: %.5f +- %.5f' % (error,std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9855 samples, validate on 657 samples\n",
      "Epoch 1/10000\n",
      "9855/9855 [==============================] - 1s 79us/step - loss: 5.7041 - val_loss: 1.0240\n",
      "Epoch 2/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.7797 - val_loss: 0.5123\n",
      "Epoch 3/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.4610 - val_loss: 0.4366\n",
      "Epoch 4/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.4093 - val_loss: 0.4049\n",
      "Epoch 5/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.3941 - val_loss: 0.3941\n",
      "Epoch 6/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.3865 - val_loss: 0.3876\n",
      "Epoch 7/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.3802 - val_loss: 0.3810\n",
      "Epoch 8/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.3727 - val_loss: 0.3717\n",
      "Epoch 9/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.3606 - val_loss: 0.3548\n",
      "Epoch 10/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.3377 - val_loss: 0.3304\n",
      "Epoch 11/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.3220 - val_loss: 0.3251\n",
      "Epoch 12/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.3157 - val_loss: 0.3177\n",
      "Epoch 13/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.3097 - val_loss: 0.3118\n",
      "Epoch 14/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.3037 - val_loss: 0.3060\n",
      "Epoch 15/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2974 - val_loss: 0.2994\n",
      "Epoch 16/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2901 - val_loss: 0.2909\n",
      "Epoch 17/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2814 - val_loss: 0.2809\n",
      "Epoch 18/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2736 - val_loss: 0.2739\n",
      "Epoch 19/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2671 - val_loss: 0.2676\n",
      "Epoch 20/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2614 - val_loss: 0.2624\n",
      "Epoch 21/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2558 - val_loss: 0.2568\n",
      "Epoch 22/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.2505 - val_loss: 0.2517\n",
      "Epoch 23/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.2453 - val_loss: 0.2463\n",
      "Epoch 24/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2401 - val_loss: 0.2421\n",
      "Epoch 25/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2351 - val_loss: 0.2361\n",
      "Epoch 26/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2301 - val_loss: 0.2320\n",
      "Epoch 27/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.2252 - val_loss: 0.2265\n",
      "Epoch 28/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2203 - val_loss: 0.2225\n",
      "Epoch 29/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.2156 - val_loss: 0.2173\n",
      "Epoch 30/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2108 - val_loss: 0.2121\n",
      "Epoch 31/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.2062 - val_loss: 0.2082\n",
      "Epoch 32/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.2016 - val_loss: 0.2033\n",
      "Epoch 33/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1970 - val_loss: 0.1987\n",
      "Epoch 34/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1926 - val_loss: 0.1941\n",
      "Epoch 35/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1883 - val_loss: 0.1900\n",
      "Epoch 36/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1840 - val_loss: 0.1857\n",
      "Epoch 37/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1796 - val_loss: 0.1815\n",
      "Epoch 38/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1755 - val_loss: 0.1771\n",
      "Epoch 39/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1713 - val_loss: 0.1732\n",
      "Epoch 40/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1674 - val_loss: 0.1693\n",
      "Epoch 41/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1634 - val_loss: 0.1656\n",
      "Epoch 42/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.1598 - val_loss: 0.1616\n",
      "Epoch 43/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1561 - val_loss: 0.1582\n",
      "Epoch 44/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1525 - val_loss: 0.1545\n",
      "Epoch 45/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1490 - val_loss: 0.1512\n",
      "Epoch 46/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1456 - val_loss: 0.1480\n",
      "Epoch 47/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1424 - val_loss: 0.1445\n",
      "Epoch 48/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1390 - val_loss: 0.1410\n",
      "Epoch 49/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1360 - val_loss: 0.1383\n",
      "Epoch 50/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1329 - val_loss: 0.1355\n",
      "Epoch 51/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1300 - val_loss: 0.1323\n",
      "Epoch 52/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1271 - val_loss: 0.1291\n",
      "Epoch 53/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1243 - val_loss: 0.1267\n",
      "Epoch 54/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.1215 - val_loss: 0.1237\n",
      "Epoch 55/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1190 - val_loss: 0.1213\n",
      "Epoch 56/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.1162 - val_loss: 0.1187\n",
      "Epoch 57/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.1135 - val_loss: 0.1160\n",
      "Epoch 58/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1111 - val_loss: 0.1134\n",
      "Epoch 59/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.1086 - val_loss: 0.1111\n",
      "Epoch 60/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.1063 - val_loss: 0.1085\n",
      "Epoch 61/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.1039 - val_loss: 0.1062\n",
      "Epoch 62/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.1016 - val_loss: 0.1039\n",
      "Epoch 63/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0994 - val_loss: 0.1021\n",
      "Epoch 64/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0973 - val_loss: 0.0996\n",
      "Epoch 65/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0951 - val_loss: 0.0973\n",
      "Epoch 66/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0932 - val_loss: 0.0955\n",
      "Epoch 67/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0912 - val_loss: 0.0937\n",
      "Epoch 68/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0893 - val_loss: 0.0917\n",
      "Epoch 69/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0873 - val_loss: 0.0893\n",
      "Epoch 70/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0855 - val_loss: 0.0878\n",
      "Epoch 71/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0836 - val_loss: 0.0858\n",
      "Epoch 72/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0818 - val_loss: 0.0840\n",
      "Epoch 73/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0800 - val_loss: 0.0824\n",
      "Epoch 74/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0783 - val_loss: 0.0804\n",
      "Epoch 75/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0767 - val_loss: 0.0789\n",
      "Epoch 76/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0751 - val_loss: 0.0776\n",
      "Epoch 77/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0737 - val_loss: 0.0757\n",
      "Epoch 78/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0721 - val_loss: 0.0742\n",
      "Epoch 79/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0706 - val_loss: 0.0730\n",
      "Epoch 80/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0691 - val_loss: 0.0713\n",
      "Epoch 81/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0677 - val_loss: 0.0697\n",
      "Epoch 82/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0663 - val_loss: 0.0685\n",
      "Epoch 83/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0649 - val_loss: 0.0670\n",
      "Epoch 84/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0636 - val_loss: 0.0658\n",
      "Epoch 85/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0624 - val_loss: 0.0651\n",
      "Epoch 86/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0611 - val_loss: 0.0634\n",
      "Epoch 87/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0599 - val_loss: 0.0624\n",
      "Epoch 88/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0586 - val_loss: 0.0610\n",
      "Epoch 89/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0576 - val_loss: 0.0599\n",
      "Epoch 90/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0563 - val_loss: 0.0585\n",
      "Epoch 91/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0552 - val_loss: 0.0573\n",
      "Epoch 92/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0541 - val_loss: 0.0563\n",
      "Epoch 93/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0531 - val_loss: 0.0557\n",
      "Epoch 94/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0521 - val_loss: 0.0545\n",
      "Epoch 95/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0510 - val_loss: 0.0532\n",
      "Epoch 96/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0501 - val_loss: 0.0523\n",
      "Epoch 97/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0491 - val_loss: 0.0516\n",
      "Epoch 98/10000\n",
      "9855/9855 [==============================] - 0s 20us/step - loss: 0.0483 - val_loss: 0.0503\n",
      "Epoch 99/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0474 - val_loss: 0.0500\n",
      "Epoch 100/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0464 - val_loss: 0.0488\n",
      "Epoch 101/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0456 - val_loss: 0.0481\n",
      "Epoch 102/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0447 - val_loss: 0.0470\n",
      "Epoch 103/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0438 - val_loss: 0.0465\n",
      "Epoch 104/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0433 - val_loss: 0.0463\n",
      "Epoch 105/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0427 - val_loss: 0.0449\n",
      "Epoch 106/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0416 - val_loss: 0.0440\n",
      "Epoch 107/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0407 - val_loss: 0.0431\n",
      "Epoch 108/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0400 - val_loss: 0.0427\n",
      "Epoch 109/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0395 - val_loss: 0.0417\n",
      "Epoch 110/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0388 - val_loss: 0.0410\n",
      "Epoch 111/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0380 - val_loss: 0.0401\n",
      "Epoch 112/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0373 - val_loss: 0.0396\n",
      "Epoch 113/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0367 - val_loss: 0.0390\n",
      "Epoch 114/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0360 - val_loss: 0.0387\n",
      "Epoch 115/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0356 - val_loss: 0.0378\n",
      "Epoch 116/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0351 - val_loss: 0.0373\n",
      "Epoch 117/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0344 - val_loss: 0.0366\n",
      "Epoch 118/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0338 - val_loss: 0.0361\n",
      "Epoch 119/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0332 - val_loss: 0.0357\n",
      "Epoch 120/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0325 - val_loss: 0.0349\n",
      "Epoch 121/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0321 - val_loss: 0.0348\n",
      "Epoch 122/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0316 - val_loss: 0.0338\n",
      "Epoch 123/10000\n",
      "9855/9855 [==============================] - 0s 19us/step - loss: 0.0312 - val_loss: 0.0334\n",
      "Epoch 124/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0306 - val_loss: 0.0329\n",
      "Epoch 125/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0301 - val_loss: 0.0324\n",
      "Epoch 126/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0296 - val_loss: 0.0320\n",
      "Epoch 127/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0292 - val_loss: 0.0319\n",
      "Epoch 128/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0288 - val_loss: 0.0319\n",
      "Epoch 129/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0286 - val_loss: 0.0310\n",
      "Epoch 130/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0279 - val_loss: 0.0302\n",
      "Epoch 131/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0276 - val_loss: 0.0305\n",
      "Epoch 132/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0273 - val_loss: 0.0295\n",
      "Epoch 133/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0269 - val_loss: 0.0292\n",
      "Epoch 134/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0263 - val_loss: 0.0286\n",
      "Epoch 135/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0258 - val_loss: 0.0282\n",
      "Epoch 136/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0255 - val_loss: 0.0280\n",
      "Epoch 137/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0251 - val_loss: 0.0276\n",
      "Epoch 138/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0248 - val_loss: 0.0272\n",
      "Epoch 139/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0246 - val_loss: 0.0270\n",
      "Epoch 140/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0242 - val_loss: 0.0268\n",
      "Epoch 141/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0239 - val_loss: 0.0262\n",
      "Epoch 142/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0235 - val_loss: 0.0256\n",
      "Epoch 143/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0233 - val_loss: 0.0259\n",
      "Epoch 144/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0230 - val_loss: 0.0255\n",
      "Epoch 145/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0228 - val_loss: 0.0251\n",
      "Epoch 146/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0223 - val_loss: 0.0248\n",
      "Epoch 147/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0221 - val_loss: 0.0248\n",
      "Epoch 148/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0221 - val_loss: 0.0247\n",
      "Epoch 149/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0220 - val_loss: 0.0241\n",
      "Epoch 150/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0215 - val_loss: 0.0242\n",
      "Epoch 151/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0218 - val_loss: 0.0247\n",
      "Epoch 152/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0210 - val_loss: 0.0234\n",
      "Epoch 153/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0206 - val_loss: 0.0228\n",
      "Epoch 154/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0204 - val_loss: 0.0226\n",
      "Epoch 155/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0200 - val_loss: 0.0228\n",
      "Epoch 156/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0200 - val_loss: 0.0223\n",
      "Epoch 157/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0197 - val_loss: 0.0218\n",
      "Epoch 158/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0193 - val_loss: 0.0216\n",
      "Epoch 159/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0192 - val_loss: 0.0216\n",
      "Epoch 160/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0194 - val_loss: 0.0222\n",
      "Epoch 161/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0193 - val_loss: 0.0210\n",
      "Epoch 162/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0189 - val_loss: 0.0215\n",
      "Epoch 163/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0188 - val_loss: 0.0210\n",
      "Epoch 164/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0183 - val_loss: 0.0206\n",
      "Epoch 165/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0181 - val_loss: 0.0202\n",
      "Epoch 166/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0181 - val_loss: 0.0204\n",
      "Epoch 167/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0179 - val_loss: 0.0202\n",
      "Epoch 168/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0177 - val_loss: 0.0199\n",
      "Epoch 169/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0175 - val_loss: 0.0204\n",
      "Epoch 170/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0175 - val_loss: 0.0196\n",
      "Epoch 171/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0171 - val_loss: 0.0197\n",
      "Epoch 172/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0171 - val_loss: 0.0200\n",
      "Epoch 173/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0171 - val_loss: 0.0197\n",
      "Epoch 174/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0170 - val_loss: 0.0194\n",
      "Epoch 175/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0168 - val_loss: 0.0188\n",
      "Epoch 176/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0164 - val_loss: 0.0186\n",
      "Epoch 177/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0164 - val_loss: 0.0188\n",
      "Epoch 178/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0164 - val_loss: 0.0184\n",
      "Epoch 179/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0162 - val_loss: 0.0189\n",
      "Epoch 180/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0160 - val_loss: 0.0182\n",
      "Epoch 181/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0158 - val_loss: 0.0185\n",
      "Epoch 182/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0157 - val_loss: 0.0179\n",
      "Epoch 183/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0155 - val_loss: 0.0178\n",
      "Epoch 184/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0155 - val_loss: 0.0184\n",
      "Epoch 185/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 186/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0153 - val_loss: 0.0180\n",
      "Epoch 187/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0152 - val_loss: 0.0175\n",
      "Epoch 188/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0153 - val_loss: 0.0176\n",
      "Epoch 189/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0153 - val_loss: 0.0185\n",
      "Epoch 190/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0152 - val_loss: 0.0173\n",
      "Epoch 191/10000\n",
      "9855/9855 [==============================] - 0s 16us/step - loss: 0.0148 - val_loss: 0.0173\n",
      "Epoch 192/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0149 - val_loss: 0.0172\n",
      "Epoch 193/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0152 - val_loss: 0.0175\n",
      "Epoch 194/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0148 - val_loss: 0.0170\n",
      "Epoch 195/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0146 - val_loss: 0.0167\n",
      "Epoch 196/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0145 - val_loss: 0.0167\n",
      "Epoch 197/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0144 - val_loss: 0.0170\n",
      "Epoch 198/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0142 - val_loss: 0.0163\n",
      "Epoch 199/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0141 - val_loss: 0.0166\n",
      "Epoch 200/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0143 - val_loss: 0.0167\n",
      "Epoch 201/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0141 - val_loss: 0.0165\n",
      "Epoch 202/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0139 - val_loss: 0.0163\n",
      "Epoch 203/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0138 - val_loss: 0.0161\n",
      "Epoch 204/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0137 - val_loss: 0.0160\n",
      "Epoch 205/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0139 - val_loss: 0.0160\n",
      "Epoch 206/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0137 - val_loss: 0.0162\n",
      "Epoch 207/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0138 - val_loss: 0.0159\n",
      "Epoch 208/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0135 - val_loss: 0.0159\n",
      "Epoch 209/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0134 - val_loss: 0.0158\n",
      "Epoch 210/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0135 - val_loss: 0.0158\n",
      "Epoch 211/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0134 - val_loss: 0.0158\n",
      "Epoch 212/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0134 - val_loss: 0.0158\n",
      "Epoch 213/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0136 - val_loss: 0.0160\n",
      "Epoch 214/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0133 - val_loss: 0.0156\n",
      "Epoch 215/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0133 - val_loss: 0.0155\n",
      "Epoch 216/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0132 - val_loss: 0.0155\n",
      "Epoch 217/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0132 - val_loss: 0.0156\n",
      "Epoch 218/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0131 - val_loss: 0.0154\n",
      "Epoch 219/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0129 - val_loss: 0.0150\n",
      "Epoch 220/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 221/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0130 - val_loss: 0.0151\n",
      "Epoch 222/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0128 - val_loss: 0.0151\n",
      "Epoch 223/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0129 - val_loss: 0.0154\n",
      "Epoch 224/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 225/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0127 - val_loss: 0.0150\n",
      "Epoch 226/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0128 - val_loss: 0.0163\n",
      "Epoch 227/10000\n",
      "9855/9855 [==============================] - 0s 18us/step - loss: 0.0128 - val_loss: 0.0149\n",
      "Epoch 228/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0127 - val_loss: 0.0151\n",
      "Epoch 229/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0127 - val_loss: 0.0150\n",
      "Epoch 230/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0127 - val_loss: 0.0154\n",
      "Epoch 231/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0129 - val_loss: 0.0148\n",
      "Epoch 232/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0126 - val_loss: 0.0150\n",
      "Epoch 233/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0127 - val_loss: 0.0154\n",
      "Epoch 234/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0128 - val_loss: 0.0151\n",
      "Epoch 235/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0132 - val_loss: 0.0151\n",
      "Epoch 236/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0129 - val_loss: 0.0157\n",
      "Epoch 237/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0127 - val_loss: 0.0150\n",
      "Epoch 238/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0124 - val_loss: 0.0149\n",
      "Epoch 239/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 240/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 241/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0150\n",
      "Epoch 242/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 243/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 244/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 245/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 246/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 247/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0153\n",
      "Epoch 248/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0122 - val_loss: 0.0146\n",
      "Epoch 249/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 250/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0147\n",
      "Epoch 251/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0148\n",
      "Epoch 252/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0148\n",
      "Epoch 253/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0119 - val_loss: 0.0150\n",
      "Epoch 254/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 255/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0118 - val_loss: 0.0142\n",
      "Epoch 256/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0117 - val_loss: 0.0147\n",
      "Epoch 257/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0145\n",
      "Epoch 258/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0142\n",
      "Epoch 259/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0117 - val_loss: 0.0144\n",
      "Epoch 260/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0117 - val_loss: 0.0146\n",
      "Epoch 261/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0122 - val_loss: 0.0149\n",
      "Epoch 262/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0146\n",
      "Epoch 263/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0119 - val_loss: 0.0144\n",
      "Epoch 264/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0118 - val_loss: 0.0151\n",
      "Epoch 265/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0118 - val_loss: 0.0144\n",
      "Epoch 266/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0118 - val_loss: 0.0144\n",
      "Epoch 267/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0117 - val_loss: 0.0142\n",
      "Epoch 268/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0118 - val_loss: 0.0142\n",
      "Epoch 269/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0118 - val_loss: 0.0142\n",
      "Epoch 270/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0117 - val_loss: 0.0146\n",
      "Epoch 271/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0116 - val_loss: 0.0143\n",
      "Epoch 272/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0117 - val_loss: 0.0148\n",
      "Epoch 273/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0114 - val_loss: 0.0142\n",
      "Epoch 274/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0114 - val_loss: 0.0144\n",
      "Epoch 275/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0115 - val_loss: 0.0142\n",
      "Epoch 276/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0117 - val_loss: 0.0141\n",
      "Epoch 277/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0116 - val_loss: 0.0139\n",
      "Epoch 278/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0117 - val_loss: 0.0143\n",
      "Epoch 279/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0117 - val_loss: 0.0142\n",
      "Epoch 280/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0116 - val_loss: 0.0144\n",
      "Epoch 281/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0115 - val_loss: 0.0142\n",
      "Epoch 282/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0118 - val_loss: 0.0144\n",
      "Epoch 283/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0114 - val_loss: 0.0142\n",
      "Epoch 284/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0114 - val_loss: 0.0140\n",
      "Epoch 285/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0113 - val_loss: 0.0139\n",
      "Epoch 286/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0113 - val_loss: 0.0142\n",
      "Epoch 287/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0114 - val_loss: 0.0143\n",
      "Epoch 288/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0113 - val_loss: 0.0140\n",
      "Epoch 289/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0116 - val_loss: 0.0148\n",
      "Epoch 290/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0114 - val_loss: 0.0142\n",
      "Epoch 291/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0114 - val_loss: 0.0141\n",
      "Epoch 292/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0113 - val_loss: 0.0142\n",
      "Epoch 293/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0114 - val_loss: 0.0147\n",
      "Epoch 294/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0116 - val_loss: 0.0151\n",
      "Epoch 295/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0114 - val_loss: 0.0151\n",
      "Epoch 296/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0114 - val_loss: 0.0140\n",
      "Epoch 297/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0112 - val_loss: 0.0139\n",
      "Epoch 298/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0113 - val_loss: 0.0139\n",
      "Epoch 299/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0112 - val_loss: 0.0141\n",
      "Epoch 300/10000\n",
      "9855/9855 [==============================] - 0s 17us/step - loss: 0.0112 - val_loss: 0.0141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad08e2a208>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=1995\n",
    "arch=(1000, 1000, 2000)\n",
    "K.clear_session()\n",
    "xv=Xt[data['year'][:-657]==k]\n",
    "yv=Yt[data['year'][:-657]==k]\n",
    "xt=Xt[data['year'][:-657]!=k]\n",
    "yt=Yt[data['year'][:-657]!=k]\n",
    "model=generate(arch,['softplus']*len(arch))\n",
    "mean=xt.mean()\n",
    "std=xt.std()\n",
    "xt=(xt-mean)/std\n",
    "xv=(xv-mean)/std\n",
    "model.fit(xt,yt,\n",
    "  epochs=10000,\n",
    "  callbacks=callbacks,\n",
    "  verbose=1,\n",
    "  batch_size=73*10, \n",
    "  validation_data=(xv,yv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2220356032249461"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xv=Xt[data['year'][:-657]==k].copy()\n",
    "yv=Yt[data['year'][:-657]==k].copy()\n",
    "xt=Xt[data['year'][:-657]!=k].copy()\n",
    "yt=Yt[data['year'][:-657]!=k].copy()\n",
    "\n",
    "mean=xt.mean()\n",
    "std=xt.std()\n",
    "xt=(xt-mean)/std\n",
    "yp = model.predict(xv)\n",
    "\n",
    "yp=np.exp(yp*np.log(10))\n",
    "yv=np.exp(yv*np.log(10))  \n",
    "evaluate(yp,yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "state": {
    "e456727b468f4df5ae70d8c4b5a914cf": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
